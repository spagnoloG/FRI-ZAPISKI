\documentclass{article}
\usepackage[margin=0.15cm]{geometry}
\usepackage{amsmath}
\usepackage{multicol}

\setlength{\columnseprule}{0.5pt}

\begin{document}

\begin{center}
    {\small TIS/FRI \par}
\end{center}

\begin{multicols}{3}

\section{Osnove}

\subsection{Ponovitev logaritmov}
\begin{small}
    \begin{itemize} 
        \item $log_a x = \dfrac{log_b x}{log_b a}$
        \item $log_b(\dfrac{x}{y}) = log_b x - log_b y$
        \item $x = b^y \implies log_b x = y$
        \item $log_2 x = log x$
        \item $0log0 = 0$
    \end{itemize}
\end{small}

\subsection{Entropija}
je povprecje vseh lastnih informacij:
\begin{center}
    \begin{math}
        H(X) = \sum_{i=1}^{n} p_i I_i = -\sum_{i=1}^{n} p_i log p_i
    \end{math}
\end{center}
Lastnosti: je zvezna, simetricna funckija (vrsni red $p_i$ ni pomemben, sestevanje je komutativno). Je vedno vecja
od 0 ($p_i \geq 0 \rightarrow -p_i \log p_i \geq 0 \rightarrow H(X) \geq 0$) in navzgor omejena z $\log n$.\\
Ce sta dogodka \textbf{neodvisna} velja aditivnost: $H(X, Y) = H(X) + H(Y)$.\\
Vec zaporednih dogodkov neodvisnega vira: $X^l = X \times \dots \times X \rightarrow H(X^l) = lH(X)$.

\section{Kodi}

\subsection{Uvod}
\textbf{Kod} sestavljajo \textit{kodne zamenjave}, ki so sestavljene iz znakov
\textbf{kodne abecede}. Stevilo znakov v kodni abecedi oznacujemo z \textbf{r}.\\
Ce so $\{p_1, \dots, p_n\}$ verjetnosti znakov $\{s_1, \dots, s_n\}$ osnovnega sporocila in $\{l_1, \dots, l_n\}$
dolzine prejetih kodnih zmanjav, je povprecna dolzina kodne zamenjave
\begin{center}
    \begin{math}
        L = \sum_{i=1}^n p_i l_i
    \end{math}
\end{center}

\subsection{Tipi kodov}
\begin{itemize}
    \item \textbf{optimalen} - ce ima najmanjso mozno dolzino kodnih zamenjav
    \item \textbf{idealen} - ce je povprecna dolzina kodnih zamenjav enaka entropiji
    \item \textbf{enakomeren} - ce je dolzina vseh kodnih zamenjav enaka
    \item \textbf{enoznacen} - ce lahko poljuben niz znakov dekodiramo na en sam nacin
    \item \textbf{trenuten} - ce lahko osnovni znak dekodiramo takoj, ko sprejmemo celotno kodno zamenjavo
\end{itemize}

\subsection{Kraftova neenakost}
Za dolzine kodnih zamenjav $\{l_1, \dots, l_n\}$ in \textit{r} znaki kodne abecede
obstaja trenutni kod, iff
\begin{center}
    \begin{math}
        \sum_{i=1}^n r^{-li} \leq 1
    \end{math}
\end{center}

\subsection{Povp. dolzina, ucinkovitost}
Najkrajse kodne zamenjave imamo, ce velja:
\begin{center}
    \begin{math}
        H_r(X) = L \rightarrow l_i = \lceil - \log_r p_i \rceil
    \end{math}
\end{center}
Ucinkovitost koda:
\begin{center}
    \begin{math}
        \eta = \dfrac{H(X)}{L \log_r}, \eta \in [0, 1]
    \end{math}
\end{center}
Kod je \textbf{gospodaren}, ce je $L$ znotraj:
\begin{center}
    \begin{math}
        H_r(X) \leq L < H_r(X) + 1
    \end{math}
\end{center}
kjer je $H_r(X)$:
\begin{center}
    \begin{math}
        H_r(X) = -\sum^{n}_{i=1} \dfrac{\log_{p_i}}{\log_r} = \dfrac{H(X)}{\log_r}
    \end{math}
\end{center}

\subsection{Shannonov prvi teorem}
Za nize neodvisnih znakov dozline \textit{n} obstajajo kodi,
za katere velja:
\begin{center}
    \begin{math}
        \lim_{n \rightarrow \infty} \dfrac{L_n}{n} = H(X)
    \end{math}
\end{center}
pri cemer je $H(X)$ entropija vira $X$.\\
Postopek kodiranja po Shannonu:
\begin{enumerate}
    \item znake razvrstimo po padajocih verjetnostih
    \item dolocimo stevilo znakov v vsaki kodni zamenjavi ($l_k$)
    \item za vse simbole izracunamo komulativne verjetnosti ($P_k = \sum_{i=1}^{k-1} p_i$)
    \item $P_k$ pretvorimo v bazo $r$. Kodno zamenjavo predstavlja prvih $l_k$ znakov necelega dela stevila
\end{enumerate}

\subsection{Fanojev kod}
Postopek kodiranja:
\begin{enumerate}
    \item znake razvrstimo po padajocih verjetnostih
    \item znake razdelimo v $r$ cim bolj enako verjetnih skupin
    \item Vsaki skupini priredimo enega od r znakov kodne abecede
    \item Deljenje ponovimo na vsaki od skupin. Postopek ponavljamo, dokler je mogoce
\end{enumerate}

\subsection{Huffmanov kod}
Huffmanov postopek kodiranja poteka od spodaj navzgor (Pri Fanoju je ravno obratno).
Pri huffmanovem kodu imamo dve fazi:
\begin{enumerate}
    \item Zdruzevanje
        \begin{enumerate}
            \item Posici r najmanj verjetnih znakov in jih zdruzi v sestavljeni znak, katerega verjetnost je vsota verjetnosti vseh znakov
            \item Preostale znake skupaj z novo sestavljenim znakom spet razvrsti
            \item Postopek ponavljaj dokler ne ostane samo r znakov
        \end{enumerate}
    \item Razdruzevanje
        \begin{enumerate}
            \item Vsakemu od preostalih znakov priredi po en znak kodirne abecede
            \item Vsak sestavljeni znak razstavi in mu priredi po en znak kodirne abecede
            \item Ko zmanjka sestavljenih znakov, je postopek zakljucen
        \end{enumerate}
\end{enumerate}
Pred kodiranjem, je vedno pametno preveriti, ce imamo zadostno stevilo znakov.
Veljati mora:
\begin{center}
    \begin{math}
        n = r + k(r-1), k \geq 0
    \end{math}
\end{center}
Ce imamo premalo znakov, jih po potrebi dodamo s verjetnostjo $p=0$.\\
Huffmanov kod lahko razsirimo tako, da vec osnovnih znakov zdruzujemo v sestavljene znake $\rightarrow$ bolj ucinkoviti kodi. Vendar
naletimo na nevarnost kombinacijske eksplozije.\\

\subsection{Aritmeticni kod}
Je \textbf{hiter} in \textbf{blizu optimalnemu} kodu, ter manj ucinkovit kot Huffmanov,
vendar se izogne kombinacijski eksploziji.
Vsak niz je predstavljen kot realno stevilo $0 \leq R < 1$, kar nam pove, da daljsi kot bo niz,
bolj natancno mora biti podano naravno stevilo $R$.\\
Postopek kodiranja(znakov ni potrebno razvrstiti):
\begin{enumerate}
    \item Zacnemo z intervalom $[0, 1)$
    \item Izbrani interval razdelimo na \textit{n} podintervalov, ki se ne prekrivajo. Sirine podintervalov ustrezajo
        verjetnostim znakov. Vsak podinterval predstavlja en znak
    \item Izberemo podinterval, ki ustreza iskanemu znaku
    \item Ce niz se ni koncan, izbrani podinterval ponovno razdelimo (bne 2.tocka)
    \item Niz lahko predstavimo s poljubnim realnim stevilom v zadnjem podintervalu
\end{enumerate}
Ko dobimo realni interval, ga samo se pretvorimo v binarnega s pomocjo klasicnega pretvarjanja
iz dec v bin stevilski sistem.

\subsection{Kod Lempel-Ziv (LZ77)} 
Stiskanje temelji na osnovi slovarja, tako, da ne potrebujemo
racunati verjetnosti za posamezne znake. \textbf{Kodirnik}
med branjem niza gradi slovar, in \textbf{dekodirnik} med branjem
kodnih zaamenjav rekonstruira slovar in znake.\\
\textbf{Kodiranje:} uporablja drseca okna, znaki se premikajo iz desne na levo.
Referenca je podana kot trojcek:
\begin{itemize}
    \item odmik - razdalja do zacetka enakega podniza v medpomnilniku
    \item dolzina enakega podniza
    \item naslednji znak
\end{itemize}
npr. (0, 0, A) - ni ujemanja, (4, 3, B) - 4 znake nazaj se ponovi 3 znakovni podniz, ki se nato zakljuci s B.\\
\textbf{dekodiranje:} sledimo kodnim zamenjavam

\subsection{Deflate}
Gre za predelan LZ77. Uporablja pare (odmik, dolzina). Ce ujemanja v kodni tabeli ni, zapise kar znak.
Uporablja dve kodni tabeli:
\begin{itemize}
    \item \textbf{tabela za znake in dolzine} - 285 simbolov
        (0-255 za osnovne znake, 256 konec bloka, 257-285 kodira dolzine)
        Kodne zamenjave brez dodatnih bitov, se zakodira s Huffmanom.
    \item \textbf{tabela odmikov}
\end{itemize}
Niz znakov se razdeli na bloke(64k)
vsak blok se kodira na enega od treh nacinov:
\begin{enumerate}
    \item \textbf{brez stiskanja} osnovni znaki se prepisejo
    \item \textbf{stiskanje s staticnim Huffmanom} (verjetnosti podane vnaprej), Huffmanovo drevo ni zakodirano v bloku
    \item \textbf{stiskanje s Huffmanom} izracunamo verjetnosti za vsak blok
\end{enumerate}
Glava posameznega bloka: 1bit - zadnji/ni zadnji blok + 2bita tip stiskanja + pri (3) se Huffmanovo drevo
Ker Huffmanovo drevo ni enolicno, uvedemo kanonicni Huffmanov kod. Postopek:
\begin{enumerate}
    \item znake razvrstimo najprej po dolzinah kodnih zamenjav in nato po abecedi
    \item prvi simbol ima same nicle
    \item vsakemu naslednjemu znaku dodelimo naslednjo binarno kodo (prejsnji + 1)
    \item ce je kodna zamenjava daljsa od binarne kode stevila, na koncu pripnemo niclo
    \item ponavjlaj (3) do konca
\end{enumerate}
Na taksen nacin dosezemo, da je potrebno kodirati samo dolzine kodnih zamenjav.

\subsection{Kod Lempel-Ziv (LZW)}
Osnovni slovar je podan in ga sporti doponjujemo. Alogritem za \textbf{kodiranje}:
\begin{verbatim}
N = ""
ponavljaj:
    preberi naslednji znak z
    ce je [N,z] v slovarju:
        N = [N, z]
    drugace:
        izpisi indeks k niza N
        dodaj [N, z] v slovar
        N = z
    izpisi indeks k niza N
\end{verbatim}
Algoritem za \textbf{dekodiranje}:
\begin{verbatim}
preberi indeks k
poisci niz N, ki ustreza indeksu k
izpisi N
L = N
ponavljaj:
    preberi indeks k
    ce je k v slovarju:
        poisci niz N
    drugace:
        N = [L, L(1)]
    izpisi N
    v slovar dodaj [L, N(1)]
    L = N
\end{verbatim}
LZW doseze optimalno stiskanje, pribliza se entropiji. % dodaj dokaz ce bo potrebno

\subsection{Verizno kodiranje ali RLE (run lenght encoding)} 
Namesto originalnih podatkov, sharnjujemo dolzino verige (fffeef $\rightarrow$ 3f2e1f).
Problemu, ko se podatki ne ponavljajo, se izognemo tako, da izvedemo kombinacijo direktnega kodiranja
in kodiranja RLE. % dodaj podrobnosti ce bo potrebno


\subsection{Stiskanje z izgubami}
S taksnim nacinom stiskanja lahko dosezemo veliko boljsa kompresijska razmerja, vendar izgubimo podatke.
Zato ga uporabljamo samo s formati, kjer se ne ukvarjamo z integriteto podatkov(MP3, MPEG, JPEG, $\dots$).
Postopki kodiranj znanih formatov:
\begin{itemize}
    \item \textbf{JPEG}
        \begin{enumerate}
            \item priprava slike $\rightarrow$ ker je svetlost bol pomembna, je barvna resolucija obicajno zmanjsana ($YC_RC_B$)
            \item aproksimacija vsake od treh komponent s 2D DCT
            \item kvantizacija $\rightarrow$  podatki ki bolj izstopajo so shranjeni manj natancno kot tisti ki so staticni
            \item kodiranje blokov s pomocjo entropije
            \item RLE cik-cak po sliki
            \item RLE kodiramo z Huffmanom ali Aritmenticnim kodom
        \end{enumerate}
    \item \textbf{MP3}
        \begin{enumerate}
            \item Modified DCT
            \item odstranitev za cloveka neslisnih frekvenc
            \item stereo, ce sta si L in R pretvorimo v mono
            \item Huffman na koncu
        \end{enumerate}
    \item \textbf{MPEG}
        \begin{enumerate}
            \item uvodno kodiranje $\rightarrow$ celotna slika JPEG
            \item nato pa kodiramo samo spremembe, ki so se zgodile v sliki JPEG s pomocjo vektorja premika. V
                primeru, da je prevec razlik, se ponovno kodira JPEG slika.
        \end{enumerate}
\end{itemize}

\subsection{Kompresijsko razmerje}
Izracunamo ga po formuli $\rightarrow$ stisnjeni binarni zapis C(M) / binarni zapis dokumenta (M):
\begin{center}
    \begin{math}
        R = C(M) / M
    \end{math}
\end{center}

\section{Kanali}

\subsection{Uvod}
Kanali so strukture, ki opisujejo medsebojno povezanost. Kanal prenasa informacijo o spemenljivki
$X$ do spremenljivke $Y$. Matematicno ga opisemo s \textbf{pogojnimi verjetnostmi}, ki povezujejo izhodne
verjetnosti z vhodom.

\subsection{Diskretni kanal brez spomina}
Povezuje diskretni nakljuicni spremenljivki, s koncno mnozico stanj $X=\{x_1, \dots, x_r\}$ in $Y=\{y_1, \dots, y_s\}$.
Obema nakljicnima spremenljivkama pripadajo tudi posamezne verjetnosti $P_X = \{p(x_1), \dots, p(x_r)\}$ in $P_Y = \{p(y_1), \dots, p(y_s)\}$. Kjer velja, da je vsota posamezne mnozice verjetnosti enaka 1. Kanal je definiran kot mnozica \textbf{pogojnih verjetnosti}
\begin{center}
    $p(y_j | x_i)$.
\end{center}
Pogojna verjetnost nam pove verjetnost za dogodek $y_j$ na izhodu iz kanala, ce je na vhodu v kanal dogodek $x_i$.
Brez spomina je zato, ker so pogojne vrjetnosti konstantne in torej neodvisne od prehodnih simbolov, velja
\begin{center}
    \begin{math}
        \sum_j p(y_j | x_i) = 1.
    \end{math} 
\end{center}
Kanal popolnoma podamo z $r \times s$ pogojnimi verjetnostmi.

\subsubsection{Binarni simetricni kanal (BSK)}
Gre za poseben primer diskretnega kanala brez spomina. Napaka kanala je $p$, saj se z verjetnostjo $p$ znak prenese
v napacnega.
\begin{center}
    \begin{math}
        P_k = 
                \begin{pmatrix}
                    1-p & p\\
                    p & 1-p 
                \end{pmatrix}
    \end{math}
\end{center}

\subsection{Pogojna entropija}
Pogojna entropija spremenljivke $Y$ pri znanem $X$ se zapise kot $H(Y|X)$.
Vzemimo, da se je zgodil dogodek $x_i \in X$. Entropija dogodka $Y$ je potem
\begin{center}
    \begin{math}
        H(Y|x_i) = - \sum_{j=1}^s p(y_j|x_i) \log(p(y_j| x_i)).
    \end{math}
\end{center}
Velja: $0 \leq H(Y| x_i)$.\\
Ce pa o dogodku X vemo le da se je zgodil, se lahko spomnemo na vis in uporabimo
\textbf{vezano verjetnost} dogodkov $X$ in $Y$, ki pravi:
\begin{center}
    \begin{math}
        p(x_i, y_j) = p(y_j|x_i)p(x_i)
    \end{math}
\end{center}
Za entropijo:
\begin{center}
    \begin{math}
        H(Y|X) = \sum_{i} p(x_i)H(Y|x_i)
    \end{math}
    \begin{math}
        = -\sum_{i=1}^r \sum_{j=1}^s p(x_i, y_i) \log p(y_j | x_i)
    \end{math}
\end{center}
Splosno velja: $0 \leq H(Y|X) \leq H(Y)$, ce poznamo spremenljivko $X$, se nedolocenost $Y$ ne more povecati (lahko se pomanjsa).

\subsection{Vezana entropija spremeljivk}
Vezana entropija nakljucnih spremenljivk $X$ in $Y$ je entropija para $(X, Y)$.
Pomembne zveze:
\begin{itemize}
    \item $p(x_i, y_j) = p(y_j| x_i)p(x_i)$,
    \item $\sum_j p(x_i, y_j) = p(x_i)$,
    \item $\sum_i p(x_i, y_j) = p(y_j)$,
    \item $\sum_{i,j} p(x_i, y_j) = 1$
\end{itemize}
Velja: $H(X, Y) = H(Y|X) + H(X)$, kar nam pove, da ce najprej izvemo, kaj se je zgodilo v dogodku $X$ in potem
dobimo se dodatne informacije od dogodku $Y$, vemo vse.
\subsubsection{Obrat kanala}
Ker velja tudi $H(X, Y) = H(X|Y) + H(Y)$, kanal lahko \textbf{obrnemo}
(sepravi vhod $Y$ in izhod $X$). Pri tem ne obracamo fizicnega procesa, ampak samo verjetnostno strukturo, ki definira kanal. \textbf{Pogoj:}  poznati moramo vhodne verjetnosti. Iz njih lahko dolocimo izhodne verjetnosti, ki jih lahko
uporabimo kot vhodne verjetnosti v obrnjeni kanal.
Lastnosti:
\begin{itemize}
    \item izracun izhodnih verjetnosti $p(y_j) = \sum_i p(y_j, x_i)p(x_i)$
    \item obratne pogojne vrjetnosti $p(x_i, y_j)= p(y_j|x_i)p(x_i) = p(x_i|y_j)p(y_j)$
\end{itemize}
Za sprejemnika sporocila so obratne pogojne verjetnosti zelo pomembne, saj z njimi lahko iz prejetih znakov doloci
verjetnost za vhodne znake.

\subsection{Medesebojna informacija}
Pove nam, koliko o eni spremenljivki izvemo iz druge spremenljivke,
definicija:
\begin{center}
    \begin{math}
        I(X;Y) = H(X) - H(X|Y)
    \end{math}
\end{center}
Lastnosti:
\begin{itemize}
    \item $I(X;Y) = H(X, Y) - H(X|Y) - H(Y|X)$
    \item $I(X;Y) = H(X) - H(X|Y)$
    \item $I(X;Y) = H(Y) - H(Y|X)$
    \item $I(X;Y) = H(X) + H(Y) - H(X, Y)$
    \item $I(X;Y) = \text{simetricna glede na } X \text{ in } Y$
    \item $I(X;Y) = -\sum_i\sum_j p(x_i, y_j) \log \frac{p(x_i)p(y_j)}{p(x_i, y_j)}$
    \item $I(X;Y) \geq 0$
    \item $I(X;X) = H(X)$
\end{itemize}

\subsection{Kapaciteta kanala}
Kapaciteta kanala je najvecja mozna medsebojna informacija, ki jo lahko prenesemo od vhoda na izhod.
\begin{center}
    $C =\underset{P(X)}{\max} I(X;Y)$
\end{center}
\subsubsection{Kapaciteta kanala BSK}
Lastnosti:
\begin{itemize}
    \item $C =\underset{P(X)}{\max} (H(Y) - H(Y|X))$
    \item $p(x_0) = \alpha, p(x_1) = 1 - \alpha$
    \item $I(X;Y) = H(Y) - H(Y|X) = \dots = H(Y) - H(p, 1-p)$
    \item $\frac{dI(X;Y)}{d \alpha} = 0$
    \item $H(Y) = 1 \Rightarrow C$ je max
    \item $C=I(X;Y) |_{\alpha = 1/2} = 1 - H(p, 1-p)$
\end{itemize}
\subsubsection{Kapacitata kanala BSK z brisanjem}
Definicija:
\begin{center}
    \begin{math}
        P_k = 
                \begin{pmatrix}
                    1-p & p & 0\\
                    0   & p & 1-p
                \end{pmatrix}
    \end{math}
\end{center}
Lastnosti:
\begin{itemize}
    \item $C = 1 - p$
    \item $p(x_0) = \alpha, p(x_1) = 1 - \alpha$
    \item $p(y_0) = (1-p)\alpha, p(y_1) = p, p(y_2) = (1-p)(1-\alpha)$
    \item $I(X;Y) = (1-p)H(\alpha, 1 - \alpha)$
    \item $\frac{dI(X;Y)}{d \alpha} = 0 \Rightarrow \alpha = 1/2$
\end{itemize}

\subsection{Shannonov drugi teorem}
Shannon je ugotovil, da nam zdruzevanje znakov v nize daje vec moznosti za doseganje zaneslijvega prenosa.\\
Naj bo $M$ stevilo razlicnih kodnih zamenjav, ki jih lahko oblikujemo z nizi dolzine $n$. Potem je \textbf{hitrost koda}
(prenosa)  definirana kot:
\begin{center}
    \begin{math}
        R = \frac{max H(X^n)}{n} = \frac{log M}{n}
    \end{math}
\end{center}
Hitrost je najvecja takrat, ko so dovoljene kodne zamenjave na vhodu enako verjetne. Shannonov teorem pravi, da je mozna
skoraj popolna komunikacija s hitrostjo, enako kapaciteti kanala.
\textbf{Teorem:}\\
\begin{center}
    Za \textbf{R $\leq$ C} obstaja kod, ki zagotavlja tako preverjanje informacije, da je verjetnost napake pri
    dekodiran  poljubno majhna. Za \textbf{R $>$ C} kod, ki bi omogocal preverjanje informacije s poljubno majhno
    verjetnostjo napake, \textbf{ne} obstaja.
\end{center}
Ce so znaki neodvisni, velja:
\begin{center}
    \begin{math}
        \log(H(X^n)) = n \log H(X) \Rightarrow R = H
    \end{math}
\end{center}
Za $R \leq \frac{\log 2^{nC}}{n} = C$ je mozno najti kodne zamenjave, ki omogocajo zanesljivo komunikacijo.

\section{Varno kodiranje}

\subsection{Uvod}
Omejili se bomo na enostavne linearne blocne kode za BSK. Dolzina bloka je $k$ znakov, abeceda je enaka abecedi
kanala, torej imamo $M=2^k$ blokov $x_1, \dots x_k$, $x_i \in \{0, 1\}$. Za potrebe varovanja dodamo se nekaj
varnostnih znakov, celotna dolzina vsake od M kodnih zamenjav je potem n. Namesto enega posljemo n enakih znakov.
Boljsi pristop pa je, da naredimo kode, kjer se povecujeta $n$ in $k$ hitreje od razilke $n -k$.

\subsection{Kontrolne vsote}
Varnost komunikacije povecamo tako, da dodamo nekaj bitov za preverjanje parnosti(paritetni biti).
Nastavljeni so tako, da je vsota bitov v aritmetiki po modulu 2 fiksna vrednost (0 ali 1).\\
\textit{Spomnimo se arsa}
\begin{center}
    \begin{tabular}{ |c|c|c| } 
        \hline
        +/-/XOR & 0 & 1 \\ 
        \hline
            0   & 0 & 1 \\ 
            1   & 1 & 0 \\ 
        \hline
    \end{tabular}
    AND $\sim \times$.\\
\end{center}

npr. $00|0, 01|1, 10|1, 11|1$(detektiramo samo eno napako).

\subsubsection{Pravokotni kodi}
Zapisemo ga v obliki pravokotnika, gledamo sodost po vrsticah in po stolpcih.

\begin{center}
    \begin{tabular}{ |c|cc| } 
        \hline
            1   & 0 & 1 \\ 
            0   & 1 & 1 \\ 
            \hline
            0   & 1 & 0 \\ 
        \hline
    \end{tabular}
\end{center}

\subsubsection{Trikotni kodi}
Vsota elementov v stolpcu in vrstici s paritetnim bitom vred mora biti soda. (ravno tako vsota paritetnih bitov)
\begin{center}
    \begin{tabular}{ ccc } 
        1   & 0 & \textbf{1} \\ 
        0   & \textbf{0} &  \\ 
        \textbf{1}   &  &  \\ 
    \end{tabular}
\end{center}

\subsection{Hammingova razdalja}
Hammingova razdalja med kodnima zamenjava nam pove stevilo znakov, na katerih se razlikujeta. Kodni zamenjavi sta enaki,
ce je razdalja 0, razdalja med razlicnimi kodi mora biti vsaj 1, drugace je kod \textbf{singularen}.
Razdalja je podana kot \textbf{minimalna} Hammingova razdalja med dvema kodnima zamenjavama.
Stevilo napak, ki jih kod zazna:
\begin{center}
    $d \geq e + 1 \rightarrow e_{max} = d-1$
\end{center}
\begin{center}
    $d \geq 2f + 1 \rightarrow f_{max} = \lfloor \frac{d-1}{2} \rfloor$
\end{center}

\subsubsection{Hammingov pogoj}
Za bloke dolzine $n$ lahko zgradimo $2^n$ razlicnih kodnih zamenjav. Ce zelimo zagotoviti odpornost na napake,
mora biti razdalja $d > 1$. Uporabni kodi imajo st. kodnih zamenjav $M = 2^k < 2^n$.
Hammingov pogoj: da bi lahko dekodirali vse kodne zamenjave, pri katerih je prislo do $e$ ali manj napak
mora veljati:
\begin{center}
    \begin{math}
        M \leq \dfrac{2^n}{\sum_{i=0}^e{n \choose i}}
    \end{math}
\end{center}

\subsection{Linearni blocni kodi}
Kode oznacimo kot dvojcek $(n, k)$. $n$ predstavlja stevilo vseh bitov, $k$ podatkovnih, $n - k$ pa st. paritetnih.
O linearnih blocnih kodih govorimo, kadar:
\begin{itemize}
    \item je vsota vsakega para kodnih zamenjav spet kodna zamenjava.
    \item da produkt kodne zamenjave z 1 in 0 spet kodno zamenjavo.
    \item vedno obstaja kodna zamenjava s samimi niclami
\end{itemize}
Oznacimo jih z $L(n, k)$. \textbf{Hammingova razdalja} linearnega koda je enaka stevilu enic v kodni zamenjavi
z najmanj enicami.
Naj bodo podatkovni biti oznaceni kot $z_1, z_2 \text{ in } z_3$, varnostni pa kot $s_1, s_2 \text{ in } s_3$:
\begin{center}
    \begin{tabular}{ ccc } 
        z\_1   & z\_2 & s\_3 \\ 
        z\_3   & s\_2 &  \\ 
        s\_1   &  & \\
    \end{tabular}
\end{center}
Potem vrednosti zlozimo v vektor, in opravimo kodno zamenjavo.
\begin{center}
    \begin{math}
        \vec{x} = (x_1, x_2, x_3, x_4, x_5, x_6) = (z_1, z_2, z_3, s_1, s_2, s_3)
    \end{math}
\end{center}
Velja:
\begin{center}
        $z_1 + z_2 + s_1 = 0 = x_1 + x_2 + x_4$\\
        $z_3 + s_2 + z_2 = 0 = x_2 + x_3 + x_5$\\
        $s_3 + s_3 + z_1 = 0 = x_1 + x_3 + x_6$\\
\end{center}


\subsubsection{Generatorska matrika}
Generiranje kodne zamenjave lahko opisemo z generatorsko matriko.

\begin{center}
    \begin{math}
        \vec{x} = \vec{z}G =  
        \begin{bmatrix}
            1 & 0 & 0 & 1 & 0 & 1\\
            0 & 1 & 0 & 1 & 1 & 0\\
            0 & 0 & 1 & 0 & 1 & 1\\ 
        \end{bmatrix}
    \end{math}
\end{center}

V splosnem podatkovni vektor $1 \times k$ mnozimo z generatorsko matriko $k \times n$, da dobimo kodno zamenjavo
$1 \times n$. Matrika mora imeti linearno neodvisne vrstice. Kod, cigar generatorska matrika ima to obliko, je
\textbf{sistematicni kod} - prvih $k$ znakov koda je enakih sporocilu (podatkovnim bitom), ostalih $n-k$ znakov pa so
paritetni biti.

Za diskretne kanale brez spomina jo vedno lahko zapisemo v obliki $G = (I_k | A)$.

\subsubsection{Matrika za preverjanje sodosti}
Linearne enacbe lahko zapisemo z matriko za preverjanje sodosti:

\begin{center}
    \begin{math}
        H =
        \begin{bmatrix}
            1 & 1 & 0 & 1 & 0 & 0 \\
            0 & 1 & 1 & 0 & 1 & 0 \\
            1 & 0 & 1 & 0 & 0 & 1 
        \end{bmatrix}
    \end{math}
\end{center}

Lastnosti:
\begin{itemize}
    \item $\vec{x}H^T = 0$
    \item $GH^T = 0$
    \item $G = (I_k | A) \Rightarrow H = (A^T | I_{n-k})$
    \item vsota dveh kodnih zamenjav je nova kodna zamenjava.
\end{itemize}

\subsection{Sindrom v kanalu}
Predpostavimo da se med posiljanjem v kanalu zgodi napaka:
\begin{center}
    \begin{math}
        z \rightarrow x = zG \rightarrow err\rightarrow y = x + e \rightarrow s = yH^T
    \end{math}
\end{center}
Napako pri prenosu preprosto ugotavljamo tako, da pogledamo, ce je $s = 0$. Vendar to nam ne garantira da pri prenosu ni prislo do napake.
Sindrom izracunamo na naslednji nacin(vektor velikosti $1 \times n - k$):
\begin{center}
    \begin{math}
        yH^T = (x + e)H^T = eH^T = s
    \end{math}
\end{center}
Ker je verjetnost za napako obicajno $p << 1$, je niz s $t$ napakami veliko
verjetnejsi od niza s t + 1 napakami.

\subsubsection{Standardna tabela}
Imejmo ponavljalni kod $(0|00)$ in $(1|11)$. Sestavimo matrki G in H.

\begin{math}
    G = [1|11] \text{ in } H = 
        \begin{bmatrix}
            1 |& 1 & 0\\
            1 |& 0 & 1
        \end{bmatrix}
\end{math}


Imamo 4 mozne sindrome: (00), (01), (10), (11). Na izhodu lahko dobimo $2^n = 8$
razlicnih nizov.

Mozne nize na izhodu in njihove sindrome obicajno razvrstimo v std. tabelo:
\begin{center}
    \begin{tabular}{ c|cc }
        \text{sindrom}   & popravljalnik & \\ 
        \hline
        00   & 000 & 111\\ 
        01   & 001 & 110\\ 
        10   & 010 & 101\\ 
        11   & 100 & 011
    \end{tabular}
\end{center}

V isti vrstici so nizi, ki dajo enak sindrom. V prvi vrstici so vedno kodne zamenjave, ki
imajo sindrom 0. Skrajno levo je vedno niz, ki ima najmanj enic, saj je najbolj verjeten.
Imenujemo ga popravljalnik. Ostale nize dobimo tako, da popravljalnik pristevamo k kodnim
zamenjavam v prvi vrsti. Popravljanje je sedaj enostavno: izracunamo sindrom, popravljalnik
odstejemo(pristejemo) od prejetega niza.

\subsection{Hammingov kod}
Hammingovi kodi so druzina linearnih blocnih kodov, ki lahko popravijo eno napako.
Najlazje jih predstavimo z matriko za preverjanje sodosti, v kateri so vsi stolpci
nenicelni vektorji. Spadajo med \textbf{popolne kode} - sfere z radijem 1 okrog kodnih
zamenjav ravno napolnijo prostor z $2^n$ tockami.

Kod z $m$ varnostnimi biti ima kodne zamenjave dolzine $2^m - 1$.  Oznaka koda je potem
$H(2^m - 1, 2^m - 1 - m)$. Ce stolpce v matriki H interpretiramo kot stevila v binarni
obliki, nam oznaka stolpca doloca polozaj napake. Stolpci v Hammingovem kodu so lahko
poljubno razmetani. Pomembno je le to, da nastopajo \textbf{vsa} stevila od 1 do $2^m - 1$.

Hammingov kod je lahko:
\begin{itemize}
    \item \textbf{leksikografski} - oznake stolpcev si sledijo po vrsti
    \item \textbf{sistematicni} - oznake stolpcev so pomesane
\end{itemize}

 V Hammingovem kodu se za varnostne bite obicajno vzamejo tisti stolpci, ki imajo samo \textbf{eno} enico.

\subsubsection{Dekodiranje}
Dekodiranje leksikografskega Hammingovega koda je preprosto:
\begin{enumerate}
    \item izracunamo sindrom $s = yH^T$
    \item ce je $s = 0$, je $x' = y$
    \item ce $s \neq 0$, decimalno stevilo $S$ predstavlja mesto napake.
\end{enumerate}
Za kod, ki pa ni leksikografski potrebujemo tabelo povezav med indeksi sindromov in stolpci(sepravi pogledamo, na kateri indeks se slika izracunani sindrom).

\subsection{Ciklicni kodi}
Ciklicni kod $C(n, k)$ je linearni blocni kod, v katerem vsak krozni premik kodne zamenjave
da drugo kodno zamenjavo. Zapisemo jih s polinomi po padajocih potencah (ravno tako jih sestevamo po mod 2). 

\subsubsection{Zapis s polinomi}
Imejmo osnovni vektor: 
\begin{center}
    $x = (x_{n-1}, x_{n-2}, \dots, x_0) \Leftrightarrow$
    $x(p) = x_{n-1}p^{n-1} + x_{n-2}p^{n-2} + \dots + x_0$ 
\end{center}
Izvedemo premik za eno mesto:
\begin{center}
    $x' = (x_{n-2}, \dots, x_0, x_{n-1}) \Leftrightarrow$
    $x'(p) = x_{n-2}p^{n-2} + \dots + x_0p + x_{n-1}$ 
\end{center}
Velja zveza: $x'(p) = px(p) - x_{n-1}(p^n -1)$.

V mod $2$ aritmetiki:
\begin{center}
    $\Rightarrow$ $x'(p) = px(p) + x_{n-1}(p^n -1)$.
\end{center}

V $\text{mod}(p^n + 1)$ aritmetiki:
\begin{center}
    $\Rightarrow$ $x'(p) = px(p) \text{ mod}(p^n + 1)$.
\end{center}

\textbf{Pozor:} aritmetiko po mod 2 izvajamo na \textbf{istih} stopnjah polinoma (na bitih), aritmetiko
po mod $(p^n + 1)$ pa na \textbf{polinomu}.

Izvajanje kroznega prekmika za $i$ mest:
\begin{center}
    \begin{math}
        x^i(p) = p^i x(p) \text{ mod} (p^n + 1)
    \end{math}
\end{center}

\subsubsection{Generatorski polinomi}
Vrstice generatorske matrike lahko razumemo kot kodne zamenjave.
Za ciklicne kode v splosnem velja: \textbf{Generatorski polinom} je stopnje $m$, kjer je $m$ stevilo
varnostnih bitov, in ga oznacimo kot:
\begin{center}
    \begin{math}
        g(p) = p^m + g_{m-1}p^{m-1} + \dots + g_1p + 1
    \end{math}
\end{center}
Za sistematicni kod velja: $G = [I_k | A_{k, n-k}]$.
Generatorska matrika:
\begin{center}
    $G= $
    \begin{tiny}
        \begin{math}
            \begin{bmatrix}
                1 & g_{m - 1} &  \dots & g_1 & 1 & 0 & \dots & 0 & 0 \\
                0 & 1         & g_{m-1} & \dots & g_1 & 1 & 0 & \dots & 0 \\
                \vdots & & & & & & & & \vdots  \\
                0 & 0 & \dots & 0 & 1 & g_{m-1} & \dots & g_1 & 1
            \end{bmatrix}
        \end{math}
    \end{tiny}
\end{center}
Sistematicni lahko dobimo z linearnimi operacijami nad vrsticami.
Velja:
\begin{center}
    \begin{math}
        p^n + 1 = g(p)h(p)
    \end{math}
\end{center}
Sepravi vsak polinom, ki polinom $p^n + 1$ deli brez ostanka, je generatorski polinom.

\subsubsection{Polinom za preverjanje sodosti}
Velja: $x(p)h(p) \mod(p^n + 1) = 0$ $\Rightarrow \sum_{i=0}^{n-i} x_i h_{j-i} = 0$

V matricni obliki: $\vec{x} H^T = H\vec{x}^T = 0$
\begin{center}
    \begin{tiny}
        \begin{math}
            \begin{bmatrix}
                h_0 & \dots & h_k & 0 & \dots & 0 & 0\\
                0 & h_0 & \dots & h_k & 0 & \dots & 0 \\
                \vdots & & & & & & \vdots \\
                0 & 0 & \dots & 0 & h_0 & \dots & h_k
            \end{bmatrix}
            \begin{bmatrix}
                x_{n-1}\\
                \vdots\\
                x_0
            \end{bmatrix} = 0
        \end{math}
    \end{tiny}
\end{center}

\subsubsection{Kodiranje z mnozenjem}
Kodne zamenjave so veckratniki generatorskega polinoma.
Velja:
\begin{center}
    \begin{math}
        x(p) = z(p) g(p) mod (p^n + 1)
    \end{math}
\end{center}, kjer je z(p) polinom, ki ustreza podatkovnemu vektorju $\vec{z}$
Kod, ki smo ga dobili z mnozenjem, ustreza generatorski matriki, ki ima v vrsticah
koeficiente $p^{k-1}g(p), \dots, pg(p), g(p)$, zato ni sistematicen.

\subsubsection{kodiranje z deljenjem}
Kodiranje na osnovi deljenja ustvari sistematicen ciklicen kod. Kodna zamenjava je zato sestavljena iz sporocila
(podatkovnega bloka) in varnostnega bloka znakov, $x = (z | r)$.
Polinom podatkovnega bloka je:
\begin{center}
    \begin{math}
        z(p) = z_{k-1}p^{n-1} + \dots + z_1p^{1} + z_0p^0
    \end{math}
\end{center}
Ce pa polinom pomnozimo s $p^m$, dobimo na desni $m$ nicel.
\begin{center}
    \begin{math}
        p^m z(p) = z_{k-1}p^{k-1} + \dots + z_1p^{m+1} + z_0p^m
    \end{math}
\end{center}
To ustreza bloku $z$, premaknjenem za $m$ znakov v levo, ($z_{k-1}, \dots, z_0, 0, \dots, 0$).

V splosnem nastavek seveda ne bo deljiv, velja pa $p^mz(p) = g(p)t(p) + r(p)$, kjer je $t(p)$ kolicnik,
$r(p)$ pa ostanek, s stopnjo manj od $m$.

Ostanek lahko zapisemo v obliki niza, kot $(0, \dots, 0, r_{m-1}, \dots, r_0)$.

Polinom $p^m z(p) + r(p) = g(p)t(p)$ je deljiv z $g(p)$ in je zato ustrazna kodna zamenjava.
Kodno zamenjavo tako dobimo, ce ostanek deljenja z generatorskim polinomom pristejemo k osnovnemu
nastavku, $(z_{k-1}, \dots, z_0 | r_{m-1}, \dots r_0)$.

\subsubsection{Strojna izvedba}
\begin{verbatim}
// todo, if needed
\end{verbatim}

\end{multicols}
\end{document}

